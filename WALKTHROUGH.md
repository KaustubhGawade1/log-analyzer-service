# ğŸš€ AI Log Analyzer & Root Cause Detection System â€” Complete Walkthrough

> **Last verified**: February 23, 2026  
> **Status**: âœ… All services running and verified

---

## ğŸ“‹ Table of Contents

1. [System Overview](#1-system-overview)
2. [Architecture](#2-architecture)
3. [Tech Stack](#3-tech-stack)
4. [Project Structure](#4-project-structure)
5. [Components Deep Dive](#5-components-deep-dive)
6. [How to Run](#6-how-to-run)
7. [Service Verification](#7-service-verification)
8. [Data Flow Walkthrough](#8-data-flow-walkthrough)
9. [API Reference](#9-api-reference)
10. [Dashboard & Visualizations](#10-dashboard--visualizations)
11. [Troubleshooting](#11-troubleshooting)

---

## 1. System Overview

This is a **production-grade observability platform** that automatically:

- ğŸ“¥ **Ingests** application logs from distributed microservices via Apache Kafka
- ğŸ” **Normalizes** sensitive data (IPs, UUIDs) for privacy compliance
- ğŸ”— **Clusters** similar errors using SHA-256 stack trace fingerprinting
- ğŸš¨ **Detects anomalies** (error bursts) using a sliding window algorithm
- ğŸ¤– **Generates AI-powered Root Cause Analysis** using Spring AI + OpenAI
- ğŸ“Š **Visualizes** distributed traces using Zipkin + React Flow
- ğŸ’¾ **Persists** logs to Elasticsearch and incidents to PostgreSQL

---

## 2. Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Log Producer       â”‚â”€â”€â”€â”€â–¶â”‚  Kafka (app-logs)   â”‚
â”‚  (Simulator)        â”‚     â”‚  Port: 9093         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  Log Analyzer Service  â”‚
                           â”‚  (Spring Boot :8080)   â”‚
                           â”‚                        â”‚
                           â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                           â”‚  â”‚ LogNormalizer     â”‚  â”‚
                           â”‚  â”‚ ErrorClusterer    â”‚  â”‚
                           â”‚  â”‚ AnomalyDetector   â”‚  â”‚
                           â”‚  â”‚ AiRootCauseServiceâ”‚  â”‚
                           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                 â–¼                 â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚Elasticsearchâ”‚    â”‚ PostgreSQL â”‚    â”‚   Alert    â”‚
           â”‚  (Logs)     â”‚    â”‚ (Incidents)â”‚    â”‚  Service   â”‚
           â”‚  :9200      â”‚    â”‚  :5432     â”‚    â”‚ (Console)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Microservices Demo Architecture (for Distributed Traces)

```
Client â†’ API Gateway â†’ User Service â†’ Order Service â†’ Inventory + Payment
         (8081)         (8082)         (8083)         (8084)    (8085)
                              â†“                          â†“
                           Zipkin (9411)              Kafka â†’ Log Analyzer
```

---

## 3. Tech Stack

| Layer             | Technology                          | Port  |
|-------------------|-------------------------------------|-------|
| **Language**      | Java 21                             | â€”     |
| **Framework**     | Spring Boot 3.5                     | â€”     |
| **Messaging**     | Apache Kafka (Confluent 7.5)        | 9093  |
| **Log Storage**   | Elasticsearch 8.11                  | 9200  |
| **Incident DB**   | PostgreSQL 16                       | 5432  |
| **AI/LLM**        | Spring AI + OpenAI GPT-3.5-turbo   | â€”     |
| **Tracing**       | Zipkin + Micrometer Brave           | 9411  |
| **Frontend**      | React + Vite + React Flow           | 5173  |
| **Build**         | Maven 3.9+                          | â€”     |
| **Containers**    | Docker Compose                      | â€”     |
| **Coordinator**   | Zookeeper                           | 2181  |

---

## 4. Project Structure

```
log-analyzer-service/                   # Root project
â”‚
â”œâ”€â”€ README.md                           # Main README
â”œâ”€â”€ INTERVIEW_PREP.md                   # Interview questions guide
â”œâ”€â”€ API_FLOW_VISUALIZER_DOCS.md         # API Flow feature docs
â”œâ”€â”€ WALKTHROUGH.md                      # This file
â”œâ”€â”€ compose.yaml                        # Root compose (Spring Boot auto-config)
â”œâ”€â”€ verify_deployment.sh                # Deployment verification script
â”‚
â”œâ”€â”€ docker/                             # Core infrastructure
â”‚   â””â”€â”€ docker-compose.yml              # Kafka, Zookeeper, ES, PostgreSQL
â”‚
â”œâ”€â”€ log-analyzer-service/               # ğŸ§  Core Analysis Engine
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ src/main/java/com/company/loganalyzer/
â”‚       â”œâ”€â”€ LogAnalyzerServiceApplication.java
â”‚       â”œâ”€â”€ ai/
â”‚       â”‚   â”œâ”€â”€ AiRootCauseService.java         # LLM Root Cause Analysis
â”‚       â”‚   â””â”€â”€ AiFlowExplanationService.java   # LLM Flow Explanations
â”‚       â”œâ”€â”€ alerting/
â”‚       â”‚   â”œâ”€â”€ AlertService.java               # Interface (Strategy Pattern)
â”‚       â”‚   â””â”€â”€ ConsoleAlertService.java         # Implementation
â”‚       â”œâ”€â”€ analysis/
â”‚       â”‚   â”œâ”€â”€ AnomalyDetector.java            # Sliding window anomaly detection
â”‚       â”‚   â”œâ”€â”€ ErrorClusterer.java             # SHA-256 error clustering
â”‚       â”‚   â””â”€â”€ LogNormalizer.java              # Regex PII masking
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â”œâ”€â”€ CorsConfig.java                 # CORS configuration
â”‚       â”‚   â”œâ”€â”€ KafkaConfig.java                # Topic constants
â”‚       â”‚   â””â”€â”€ ZipkinConfig.java               # Zipkin REST client config
â”‚       â”œâ”€â”€ controller/
â”‚       â”‚   â”œâ”€â”€ ApiController.java              # Log/Incident REST API
â”‚       â”‚   â””â”€â”€ FlowController.java             # Flow visualization API
â”‚       â”œâ”€â”€ flow/                               # API Flow Visualizer
â”‚       â”‚   â”œâ”€â”€ entity/                         # JPA entities
â”‚       â”‚   â”œâ”€â”€ model/                          # Domain models
â”‚       â”‚   â”œâ”€â”€ repository/                     # Data access
â”‚       â”‚   â””â”€â”€ service/                        # Business logic
â”‚       â”œâ”€â”€ ingestion/
â”‚       â”‚   â””â”€â”€ LogIngestionService.java        # Kafka consumer & pipeline
â”‚       â”œâ”€â”€ model/
â”‚       â”‚   â”œâ”€â”€ LogEvent.java                   # Java Record (Kafka DTO)
â”‚       â”‚   â”œâ”€â”€ LogDocument.java                # ES document
â”‚       â”‚   â””â”€â”€ IncidentEntity.java             # JPA entity
â”‚       â””â”€â”€ repository/
â”‚           â”œâ”€â”€ LogRepository.java              # Elasticsearch
â”‚           â””â”€â”€ IncidentRepository.java         # PostgreSQL
â”‚
â”œâ”€â”€ log-producer-simulator/             # ğŸ“¤ Synthetic Log Generator
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ src/main/java/
â”‚       â””â”€â”€ LogGenerator.java                   # Scheduled Kafka producer
â”‚
â”œâ”€â”€ microservices-demo/                 # ğŸŒ 5-Service Demo Environment
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ docker-compose.yml              # Full stack with Zipkin + Kafka
â”‚   â”œâ”€â”€ demo.sh                         # Traffic generation script
â”‚   â”œâ”€â”€ pom.xml                         # Parent POM
â”‚   â”œâ”€â”€ api-gateway/         (8081)     # Entry point, routing
â”‚   â”œâ”€â”€ user-service/        (8082)     # User management
â”‚   â”œâ”€â”€ order-service/       (8083)     # Order orchestration
â”‚   â”œâ”€â”€ inventory-service/   (8084)     # Stock management
â”‚   â””â”€â”€ payment-service/     (8085)     # Payment processing
â”‚
â””â”€â”€ dashboard/                          # ğŸ“Š React Frontend
    â”œâ”€â”€ package.json
    â”œâ”€â”€ vite.config.js
    â””â”€â”€ src/
        â”œâ”€â”€ App.jsx                     # Router with lazy loading
        â”œâ”€â”€ components/
        â”‚   â”œâ”€â”€ Sidebar.jsx             # Navigation
        â”‚   â””â”€â”€ graph/                  # React Flow components
        â”‚       â”œâ”€â”€ FlowGraph.jsx       # Flow graph visualization
        â”‚       â”œâ”€â”€ ServiceNode.jsx     # Custom service node
        â”‚       â””â”€â”€ FlowEdge.jsx        # Custom edge with metrics
        â”œâ”€â”€ pages/
        â”‚   â”œâ”€â”€ Dashboard.jsx           # Main dashboard
        â”‚   â”œâ”€â”€ ApiFlows.jsx            # API Flow Explorer
        â”‚   â”œâ”€â”€ Incidents.jsx           # Incident management
        â”‚   â”œâ”€â”€ LogExplorer.jsx         # Log search
        â”‚   â””â”€â”€ ErrorClusters.jsx       # Error cluster view
        â””â”€â”€ services/
            â””â”€â”€ api.js                  # Backend API client
```

---

## 5. Components Deep Dive

### 5.1 Log Analyzer Service (Core Engine)

The heart of the system. Receives logs from Kafka, processes them through a pipeline, and stores results.

**Processing Pipeline (in `LogIngestionService.java`):**
1. **Normalize** â†’ Mask IPs, UUIDs, numbers via regex
2. **Cluster** â†’ Generate SHA-256 fingerprint from normalized message + stack trace
3. **Persist** â†’ Save to Elasticsearch
4. **Detect Anomalies** â†’ Sliding window error burst detection
5. **Create Incident** â†’ Store in PostgreSQL if anomaly detected
6. **Alert** â†’ Log `[ALERT]` to console

**Key Algorithms:**
- **Normalization**: Regex-based PII masking (`\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}` â†’ `<IP>`)
- **Clustering**: SHA-256 hash of normalized message + first 3 lines of stack trace
- **Anomaly Detection**: `ConcurrentHashMap<String, Deque<Instant>>` with 60-second sliding window, threshold of 5 errors

### 5.2 Log Producer Simulator

Generates realistic synthetic logs with:
- Random service names
- Varying log levels (INFO, WARN, ERROR)
- Stack traces for errors
- Configurable error rates
- Scheduled via `@Scheduled`

### 5.3 Microservices Demo (5 Services)

A complete e-commerce microservices setup that:
- Generates **distributed traces** for the API Flow Visualizer
- Sends **logs to Kafka** for the Log Analyzer
- Supports **chaos engineering** (random latency, error injection)

**Order Flow:**
```
API Gateway (8081)
  â””â”€ GET /api/users/{id} â†’ User Service (8082) â†’ Validates user
  â””â”€ POST /orders â†’ Order Service (8083)
       â””â”€ POST /inventory/reserve â†’ Inventory Service (8084)
       â””â”€ POST /payments/process â†’ Payment Service (8085)
```

Each service:
- Reports traces to **Zipkin** via Micrometer Brave
- Forwards logs to **Kafka** (`app-logs` topic) via `KafkaLogForwarder`
- Supports chaos mode via environment variables

### 5.4 Dashboard (React Frontend)

5 pages with a dark-themed, glassmorphism UI:

| Page | Route | Description |
|------|-------|-------------|
| Dashboard | `/` | Incident summary, data pipelines, log timeline |
| Incidents | `/incidents` | View/manage detected incidents |
| Log Explorer | `/logs` | Full-text search through ingested logs |
| Error Clusters | `/clusters` | View grouped errors by fingerprint |
| API Flows | `/flows` | React Flow visualization of distributed traces |

### 5.5 API Flow Visualizer

Connects to **Zipkin** to fetch distributed traces, converts them to interactive node graphs:
- **FlowGraphBuilder** â†’ Converts Zipkin spans to nodes/edges
- **BottleneckDetector** â†’ Identifies high latency, error rates, cascading failures
- **AI Explanation** â†’ Uses OpenAI to explain complex call graphs

---

## 6. How to Run

### Prerequisites
- Java 21 (JDK)
- Docker & Docker Compose
- Maven 3.9+
- Node.js 18+ & npm
- (Optional) OpenAI API Key for AI features

### Step 1: Start Infrastructure (Docker)

```bash
cd /home/kaustubhgawade/Downloads/log-analyzer-service

# Start Kafka, Zookeeper, Elasticsearch, PostgreSQL
docker compose -f docker/docker-compose.yml up -d

# Start Zipkin (for distributed tracing)
docker run -d --name zipkin -p 9411:9411 openzipkin/zipkin
```

**Verify infrastructure:**
```bash
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
```

Expected containers:
| Container        | Port |
|------------------|------|
| kafka            | 9093 |
| zookeeper        | 2181 |
| elasticsearch    | 9200 |
| postgres         | 5432 |
| demo-zipkin      | 9411 |

### Step 2: Build All Services

```bash
# Build the core log analyzer
cd log-analyzer-service && mvn clean install -DskipTests && cd ..

# Build the log producer simulator
cd log-producer-simulator && mvn clean install -DskipTests && cd ..

# Build all 5 microservices
cd microservices-demo && mvn clean install -DskipTests && cd ..
```

### Step 3: Start the Log Analyzer Service (Core Backend)

```bash
# Optional: Set OpenAI key for AI features
export OPENAI_API_KEY=sk-your-key-here

# Start on port 8080
java -jar log-analyzer-service/target/log-analyzer-service-0.0.1-SNAPSHOT.jar &
```

### Step 4: Start the 5 Microservices

```bash
cd microservices-demo

# Start each service (each in its own terminal or background)
mvn spring-boot:run -pl api-gateway &
mvn spring-boot:run -pl user-service &
mvn spring-boot:run -pl order-service &
mvn spring-boot:run -pl inventory-service &
mvn spring-boot:run -pl payment-service &
```

### Step 5: Start the Dashboard (Frontend)

```bash
cd dashboard
npm install   # First time only
npm run dev
```

### Step 6: Generate Demo Traffic

```bash
cd microservices-demo
chmod +x demo.sh
./demo.sh http://localhost:8081 10 2
```

Or manually test:
```bash
# Health check
curl http://localhost:8081/api/health

# Full order flow (creates traces through all 5 services)
curl -X POST http://localhost:8081/api/orders \
  -H "Content-Type: application/json" \
  -d '{"userId":"user-1","productId":"product-1","quantity":2,"amount":59.98}'
```

### Step 7: Start Log Producer Simulator (Optional)

```bash
java -jar log-producer-simulator/target/log-producer-simulator-0.0.1-SNAPSHOT.jar &
```

---

## 7. Service Verification

### All Service URLs

| Service                  | URL                              | Status |
|--------------------------|----------------------------------|--------|
| **Log Analyzer API**     | http://localhost:8080             | âœ…     |
| **API Gateway**          | http://localhost:8081/api/health  | âœ…     |
| **User Service**         | http://localhost:8082/users/user-1| âœ…     |
| **Order Service**        | http://localhost:8083             | âœ…     |
| **Inventory Service**    | http://localhost:8084/inventory/product-1 | âœ… |
| **Payment Service**      | http://localhost:8085             | âœ…     |
| **Dashboard**            | http://localhost:5173             | âœ…     |
| **API Flow Visualizer**  | http://localhost:5173/flows       | âœ…     |
| **Zipkin UI**            | http://localhost:9411             | âœ…     |
| **Elasticsearch**        | http://localhost:9200             | âœ…     |

### Quick Health Check Script

```bash
for port in 8080 8081 8082 8083 8084 8085; do
  echo -n "Port $port: "
  curl -s -o /dev/null -w "%{http_code}" http://localhost:$port/ 2>/dev/null
  echo ""
done
```

---

## 8. Data Flow Walkthrough

### Flow 1: Log Ingestion & Analysis

```
1. Log Producer Simulator generates LogEvent:
   {serviceName: "order-service", level: "ERROR", message: "...", stackTrace: "..."}

2. LogEvent â†’ Kafka topic "app-logs" (port 9093)

3. LogIngestionService (@KafkaListener) consumes:
   a. LogNormalizer masks IPs/UUIDs â†’ "Connection timeout from <IP> for user <UUID>"
   b. ErrorClusterer generates SHA-256 fingerprint â†’ "a1b2c3d4e5f67890"
   c. LogDocument saved to Elasticsearch (searchable)
   d. AnomalyDetector checks sliding window â†’ ERROR_BURST if >5 errors/60s
   e. IncidentEntity created in PostgreSQL
   f. ConsoleAlertService logs [ALERT]

4. Dashboard queries:
   - GET /api/incidents â†’ PostgreSQL incidents
   - GET /api/logs â†’ Elasticsearch logs
   - GET /api/logs/clusters â†’ Grouped by cluster ID
```

### Flow 2: Distributed Trace Visualization

```
1. Client calls POST /api/orders on API Gateway (8081)

2. API Gateway:
   â””â”€ Creates Zipkin span (root)
   â””â”€ Calls User Service (8082) â†’ child span
   â””â”€ Calls Order Service (8083) â†’ child span
       â””â”€ Order Service calls Inventory (8084) â†’ child span
       â””â”€ Order Service calls Payment (8085) â†’ child span

3. All spans sent to Zipkin (9411)

4. KafkaLogForwarder in each service sends logs to Kafka

5. Dashboard (API Flow Explorer):
   - Fetches traces from Zipkin via backend
   - FlowGraphBuilder converts spans to graph
   - BottleneckDetector flags slow/failing services
   - React Flow renders interactive visualization
```

### Flow 3: AI Root Cause Analysis

```
1. Incident detected (ERROR_BURST in payment-service)

2. User triggers: POST /api/incidents/{id}/analyze

3. AiRootCauseService:
   a. Fetches incident + related logs from ES
   b. Constructs prompt (system + user context)
   c. Calls OpenAI GPT-3.5-turbo via Spring AI
   d. Receives structured JSON: {summary, rootCause, actions, confidence}

4. Response returned to dashboard for display
```

---

## 9. API Reference

### Log Analyzer Service (Port 8080)

| Method | Endpoint                       | Description                    |
|--------|--------------------------------|--------------------------------|
| GET    | `/api/incidents`               | List all incidents             |
| GET    | `/api/incidents/{id}`          | Get incident details           |
| POST   | `/api/incidents/{id}/analyze`  | Trigger AI Root Cause Analysis |
| GET    | `/api/logs`                    | List recent logs               |
| GET    | `/api/logs/clusters`           | List error clusters            |
| GET    | `/api/logs/timeline`           | Log activity timeline          |

### Flow Endpoints (Port 8080)

| Method | Endpoint                          | Description                 |
|--------|-----------------------------------|-----------------------------|
| GET    | `/api/flows/services`             | List services from Zipkin   |
| GET    | `/api/flows/dependencies`         | Service dependency graph    |
| GET    | `/api/flows/traces`               | List recent traces          |
| GET    | `/api/flows/{traceId}`            | Get flow graph for a trace  |
| GET    | `/api/flows/bottlenecks`          | Flows with detected issues  |
| POST   | `/api/flows/{traceId}/explain`    | AI explanation for flow     |
| GET    | `/api/flows/stats`                | Flow statistics             |
| GET    | `/api/flows/topology`             | Complete topology           |

### Microservices Demo

| Service           | Port | Key Endpoints                          |
|-------------------|------|----------------------------------------|
| **API Gateway**   | 8081 | `GET /api/health`, `POST /api/orders`  |
| **User Service**  | 8082 | `GET /users/{id}`, `POST /users/{id}/validate` |
| **Order Service** | 8083 | `POST /orders`, `GET /orders/{id}`     |
| **Inventory**     | 8084 | `GET /inventory/{id}`, `POST /inventory/reserve` |
| **Payment**       | 8085 | `POST /payments/process`, `GET /payments/{id}/status` |

---

## 10. Dashboard & Visualizations

### Main Dashboard (`/`)
- **Incident Summary**: Total, Open, Resolved, Error Bursts
- **Data Pipelines**: Kafka (log ingestion status), Zipkin (trace pipeline status)
- **Log Activity Timeline**: Real-time chart of log volume (last 60 mins)

### Incidents (`/incidents`)
- List all detected anomaly incidents
- View details per incident
- Trigger AI analysis

### Log Explorer (`/logs`)
- Full-text search across all ingested logs
- Filter by service, level, time range

### Error Clusters (`/clusters`)
- Errors grouped by SHA-256 fingerprint
- Shows count, first/last seen

### API Flow Explorer (`/flows`)
- Interactive service graph powered by React Flow
- Lists recent traces with latency metrics
- Click a trace to see the full distributed call graph
- AI explanation generator for complex flows

### Zipkin UI (`http://localhost:9411`)
- Native Zipkin interface for exploring raw spans
- Service dependency graph
- Latency distributions

---

## 11. Troubleshooting

### Kafka Not Starting
```bash
# Check Kafka logs
docker logs kafka

# Restart infrastructure
docker compose -f docker/docker-compose.yml down
docker compose -f docker/docker-compose.yml up -d
```

### Port Conflicts
| Service | Default Port | Fix |
|---------|-------------|-----|
| Kafka   | 9093        | Change in `docker-compose.yml` |
| ES      | 9200        | Change in `docker-compose.yml` |
| Postgres| 5432        | Change in `docker-compose.yml` |
| Backend | 8080        | Change `server.port` in `application.yml` |

### Deserialization Errors
If you see `RecordDeserializationException`, ensure `application.yml` has:
```yaml
spring.json.value.default.type: "com.company.loganalyzer.model.LogEvent"
```

### CORS Errors
Frontend ports (5173-5175) are whitelisted in `CorsConfig.java`.

### Spring Boot Docker Compose Auto-Config
If backend fails with "No Docker Compose file found", ensure:
```yaml
spring:
  docker:
    compose:
      enabled: false
```

### Checking Process Status
```bash
# Find Java processes
ps aux | grep java | grep -v grep

# Kill a specific service
kill $(lsof -t -i:8081)
```

---

## Design Patterns Used

| Pattern                | Where Used                    | Purpose                        |
|------------------------|-------------------------------|--------------------------------|
| **Strategy**           | `AlertService` interface      | Swap alert implementations     |
| **Pipeline**           | `LogIngestionService`         | Sequential processing stages   |
| **Repository**         | Spring Data JPA/ES            | Abstract data access           |
| **Builder**            | `ChatClient.prompt()`         | Fluent API for LLM calls       |
| **DI (Constructor)**   | All services                  | Loose coupling, testability    |
| **Observer**           | `@KafkaListener`              | Event-driven log consumption   |
| **Fingerprinting**     | `ErrorClusterer`              | Content-based deduplication    |

---

*This walkthrough was generated and verified with all services running on February 23, 2026.*
